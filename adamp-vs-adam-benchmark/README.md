# ğŸ§  AdamP vs Adam Optimizer Benchmark

This project compares the performance of two popular deep learning optimizersâ€”**Adam** and **AdamP**â€”across two benchmark datasets: **FashionMNIST** and **CIFAR-10**.  
The goal is to evaluate:

- âš¡ Training efficiency  
- ğŸ“‰ Convergence speed  
- ğŸ¯ Final accuracy  

---

## ğŸ“ Project Structure

| Folder         | Description                                                                 |
|----------------|-----------------------------------------------------------------------------|
| `cifar10/`      | Code and notebooks for benchmarking Adam vs AdamP on the CIFAR-10 dataset |
| `fashionmnist/` | Code and notebooks for benchmarking Adam vs AdamP on the FashionMNIST dataset |

---

## ğŸ’¡ Optimizer Concepts

- **Adam (Adaptive Moment Estimation)**  
  Combines Momentum and RMSprop. It adapts learning rates for each parameter using estimates of first and second moments of gradients. Known for fast convergence and robustness.

- **AdamP (Adam with Projection)**  
  Enhances Adam by introducing a projection step that helps avoid poor generalization caused by over-adaptive updates. Especially useful in vision tasks and models with large parameter spaces.

---

## ğŸ““ Open Notebooks in Google Colab

Launch the notebooks directly in Google Colab:

- **CIFAR-10 Benchmark**  
  [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/youngho-kwon-class/ml-edu-lab/blob/main/adamp-vs-adam-benchmark/cifar10/adam-benchmark-cifar10.ipynb)

- **FashionMNIST Benchmark**  
  [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/youngho-kwon-class/ml-edu-lab/main/adamp-vs-adam-benchmark/fashionmnist/adam-benchmark-fashionmnist.ipynb)


---

## ğŸ“Š Potential Extensions

Want to take this further? Consider adding:

- ğŸ“ˆ Visualizations of loss and accuracy curves for both optimizers  
- ğŸ§ª Tests on additional datasets like SVHN or TinyImageNet  
- ğŸ§  Integration with different model architectures (e.g., ResNet, EfficientNet)

---
